{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Considering the problem of matrix factorization $Y=W^\\top X$, where $Y\\in \\mathbb{R}^{m\\times n}$ is the observed data matrix, $W\\in\\mathbb{R}^{m\\times r}$ and $X\\in \\mathbb{R}^{n\\times r}$ are two latent feature matrices. \n",
    "\n",
    "#### Loss\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "L &= ||Y - W^\\top X||_F^2\\\\\n",
    "~ &= \\text{tr}\\left((Y-WX^\\top)^\\top(Y-WX^\\top)\\right)\\\\\n",
    "~ &= \\text{tr}(Y^\\top Y)-\\text{tr}(XW^\\top Y) - \\text{tr}(Y^\\top WX^\\top)+\\text{tr}(XW^\\top WX^\\top)\\\\\n",
    "~ &= \\text{tr}(Y^\\top Y)-\\text{tr}(YXW^\\top) - \\text{tr}(X^\\top Y^\\top W)+\\text{tr}(WX^\\top XW^\\top)\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "#### Derivative\n",
    "\n",
    "$$\n",
    "\\frac{\\partial L}{\\partial X} = -Y^\\top W + XW^\\top W\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\frac{\\partial L}{\\partial W} = -Y X + WX^\\top X\n",
    "$$\n",
    "\n",
    "#### Backpropagation\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "W^{(k+1)} &= W^{(k)} - \\eta \\frac{\\partial L}{\\partial W}|_{W^{(k)}}\\\\\n",
    "~& = W^{(k)} - \\eta (-YX^{(k)}+W^{(k)}X^{(k)\\top}X^{(k)})\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape:\n",
      "(323, 17568)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "directory = '../../datasets/Seattle_loop-data-set/'\n",
    "A = np.load( directory + 'Loop_Seattle_2015_A.npy')\n",
    "dense_mat = np.load( directory + 'dense_mat.npy')\n",
    "\n",
    "print('Dataset shape:')\n",
    "print(dense_mat.shape)\n",
    "\n",
    "missing_rate = 0.0\n",
    "# =============================================================================\n",
    "### Random missing (PM) scenario\n",
    "### Set the PM scenario by:\n",
    "rm_random_mat = np.load(directory + 'rm_random_mat.npy')\n",
    "binary_mat = np.round(rm_random_mat + 0.5 - missing_rate)\n",
    "# =============================================================================\n",
    "# =============================================================================\n",
    "### Non-random missing (CM) scenario\n",
    "### Set the CM scenario by:\n",
    "# nm_random_mat = np.load(directory + 'nm_random_mat.npy')\n",
    "# binary_tensor = np.zeros((dense_mat.shape[0], 61, 288))\n",
    "# for i1 in range(binary_tensor.shape[0]):\n",
    "#     for i2 in range(binary_tensor.shape[1]):\n",
    "#         binary_tensor[i1, i2, :] = np.round(nm_random_mat[i1, i2] + 0.5 - missing_rate)\n",
    "# binary_mat = binary_tensor.reshape([binary_tensor.shape[0], binary_tensor.shape[1] * binary_tensor.shape[2]])\n",
    "# =============================================================================\n",
    "\n",
    "sparse_mat = np.multiply(dense_mat, binary_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:\n",
      "6.573608615534675e+17\n",
      "\n",
      "Loss:\n",
      "8.239645759727858e+93\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:9: RuntimeWarning: overflow encountered in matmul\n",
      "  if __name__ == '__main__':\n",
      "C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:9: RuntimeWarning: invalid value encountered in add\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:\n",
      "inf\n",
      "\n",
      "Loss:\n",
      "nan\n",
      "\n",
      "Loss:\n",
      "nan\n",
      "\n",
      "Loss:\n",
      "nan\n",
      "\n",
      "Loss:\n",
      "nan\n",
      "\n",
      "Loss:\n",
      "nan\n",
      "\n",
      "Loss:\n",
      "nan\n",
      "\n",
      "Loss:\n",
      "nan\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rank = 60\n",
    "dim1, dim2 = sparse_mat.shape\n",
    "W = np.random.rand(dim1, rank)\n",
    "X = np.random.rand(dim2, rank)\n",
    "Maxiter = 10\n",
    "eta = 0.01\n",
    "for i in range(Maxiter):\n",
    "    W = W - eta * (- sparse_mat @ X + W @ X.T @ X)\n",
    "    X = X - eta * (- sparse_mat.T @ W + X @ W.T @ W)\n",
    "    print('Loss:')\n",
    "    print(np.linalg.norm((sparse_mat - W @ X.T), 'fro'))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
