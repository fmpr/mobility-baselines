{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.utils.data as utils\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch.nn.parameter import Parameter\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2.0+cpu\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PrepareDataset(sparse_mat, dense_mat, BATCH_SIZE = 40, time_lags = np.array([1, 2, 288]), pred_len = 1, valid_len = 2882, test_len = 1441):\n",
    "    \"\"\" Prepare training and testing datasets and dataloaders.\n",
    "    \n",
    "    Convert speed/volume/occupancy matrix to training and testing dataset. \n",
    "    The vertical axis of speed_matrix is the time axis and the horizontal axis \n",
    "    is the spatial axis.\n",
    "    \n",
    "    Args:\n",
    "        speed_matrix: a Matrix containing spatial-temporal speed data for a network\n",
    "        seq_len: length of input sequence\n",
    "        pred_len: length of predicted sequence\n",
    "    Returns:\n",
    "        Training dataloader\n",
    "        Testing dataloader\n",
    "    \"\"\"\n",
    "    time_len = sparse_mat.shape[0]\n",
    "    \n",
    "    #speed_matrix = speed_matrix.clip(0, 100)\n",
    "    \n",
    "    max_speed = np.max(sparse_mat)\n",
    "    sparse_mat =  sparse_mat / max_speed\n",
    "    dense_mat = dense_mat / max_speed\n",
    "    max_lag = np.max(time_lags)\n",
    "    speed_sequences, speed_sequences_dense, speed_labels = [], [], []\n",
    "    for i in range(time_len - max_lag - pred_len + 1):\n",
    "        speed_sequences.append(sparse_mat[i+time_lags-1, :])\n",
    "        speed_sequences_dense.append(dense_mat[i+time_lags-1, :])\n",
    "        speed_labels.append(dense_mat[i+max_lag:i+max_lag+pred_len, :])\n",
    "    speed_sequences, speed_labels = np.asarray(speed_sequences), np.asarray(speed_labels)\n",
    "    sample_size = speed_sequences.shape[0]\n",
    "    \n",
    "#     test_len = int(sample_size * test_proportion)\n",
    "#     valid_len = int(sample_size * valid_proportion)\n",
    "    train_index = sample_size - test_len - valid_len\n",
    "    valid_index = train_index + valid_len\n",
    "    \n",
    "    train_data, train_label = speed_sequences[:train_index], speed_labels[:train_index]\n",
    "    valid_data, valid_label = speed_sequences[train_index:valid_index], speed_labels[train_index:valid_index]\n",
    "    test_data, test_label = speed_sequences[valid_index:], speed_labels[valid_index:]\n",
    "    \n",
    "    train_data, train_label = torch.Tensor(train_data), torch.Tensor(train_label)\n",
    "    valid_data, valid_label = torch.Tensor(valid_data), torch.Tensor(valid_label)\n",
    "    test_data, test_label = torch.Tensor(test_data), torch.Tensor(test_label)\n",
    "\n",
    "    train_dataset = utils.TensorDataset(train_data, train_label)\n",
    "    valid_dataset = utils.TensorDataset(valid_data, valid_label)\n",
    "    test_dataset = utils.TensorDataset(test_data, test_label)\n",
    "    print()\n",
    "    print('Test_set shape:')\n",
    "    print(test_data.shape)\n",
    "    train_dataloader = utils.DataLoader(train_dataset, batch_size = BATCH_SIZE, shuffle=True, drop_last = True)\n",
    "    valid_dataloader = utils.DataLoader(valid_dataset, batch_size = BATCH_SIZE, shuffle=True, drop_last = True)\n",
    "    test_dataloader = utils.DataLoader(test_dataset, batch_size = test_data.shape[0], shuffle=True, drop_last = True)\n",
    "    return train_dataloader, valid_dataloader, test_dataloader, max_speed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TrainModel(model, train_dataloader, valid_dataloader, learning_rate = 1e-5, num_epochs = 300, patience = 10, min_delta = 0.00001):\n",
    "    \n",
    "    inputs, labels = next(iter(train_dataloader))\n",
    "    [batch_size, step_size, fea_size] = inputs.size()\n",
    "    input_dim = fea_size\n",
    "    hidden_dim = fea_size\n",
    "    output_dim = fea_size\n",
    "    \n",
    "    #model.cuda()\n",
    "    \n",
    "    loss_MSE = torch.nn.MSELoss()\n",
    "    loss_L1 = torch.nn.L1Loss()\n",
    "\n",
    "    learning_rate = 1e-5\n",
    "    optimizer = torch.optim.RMSprop(model.parameters(), lr = learning_rate)\n",
    "    \n",
    "    use_gpu = torch.cuda.is_available()\n",
    "    \n",
    "    interval = 100\n",
    "    losses_train = []\n",
    "    losses_valid = []\n",
    "    losses_epochs_train = []\n",
    "    losses_epochs_valid = []\n",
    "    \n",
    "    cur_time = time.time()\n",
    "    pre_time = time.time()\n",
    "    \n",
    "    # Variables for Early Stopping\n",
    "    is_best_model = 0\n",
    "    patient_epoch = 0\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "#         print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "#         print('-' * 10)\n",
    "        \n",
    "        trained_number = 0\n",
    "        \n",
    "        valid_dataloader_iter = iter(valid_dataloader)\n",
    "        \n",
    "        losses_epoch_train = []\n",
    "        losses_epoch_valid = []\n",
    "\n",
    "        for data in train_dataloader:\n",
    "            inputs, labels = data\n",
    "\n",
    "            if inputs.shape[0] != batch_size:\n",
    "                continue\n",
    "\n",
    "            if use_gpu:\n",
    "                inputs, labels = Variable(inputs.cuda()), Variable(labels.cuda())\n",
    "            else: \n",
    "                inputs, labels = Variable(inputs), Variable(labels)\n",
    "                \n",
    "            model.zero_grad()\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            \n",
    "            loss_train = loss_MSE(outputs, torch.squeeze(labels))\n",
    "            \n",
    "            losses_train.append(loss_train.data)\n",
    "            losses_epoch_train.append(loss_train.data)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            loss_train.backward()\n",
    "            \n",
    "            optimizer.step()\n",
    "            \n",
    "            # validation \n",
    "            try: \n",
    "                inputs_val, labels_val = next(valid_dataloader_iter)\n",
    "            except StopIteration:\n",
    "                valid_dataloader_iter = iter(valid_dataloader)\n",
    "                inputs_val, labels_val = next(valid_dataloader_iter)\n",
    "            \n",
    "            if use_gpu:\n",
    "                inputs_val, labels_val = Variable(inputs_val.cuda()), Variable(labels_val.cuda())\n",
    "            else: \n",
    "                inputs_val, labels_val = Variable(inputs_val), Variable(labels_val)\n",
    "\n",
    "            outputs_val= model(inputs_val)\n",
    "\n",
    "            loss_valid = loss_MSE(outputs_val, torch.squeeze(labels_val))\n",
    "            losses_valid.append(loss_valid.data)\n",
    "            losses_epoch_valid.append(loss_valid.data)\n",
    "            \n",
    "            # output\n",
    "            trained_number += 1\n",
    "            \n",
    "        avg_losses_epoch_train = sum(losses_epoch_train) / float(len(losses_epoch_train))\n",
    "        avg_losses_epoch_valid = sum(losses_epoch_valid) / float(len(losses_epoch_valid))\n",
    "        losses_epochs_train.append(avg_losses_epoch_train)\n",
    "        losses_epochs_valid.append(avg_losses_epoch_valid)\n",
    "        \n",
    "        # Early Stopping\n",
    "        if epoch == 0:\n",
    "            is_best_model = 1\n",
    "            best_model = model\n",
    "            min_loss_epoch_valid = 10000.0\n",
    "            if avg_losses_epoch_valid < min_loss_epoch_valid:\n",
    "                min_loss_epoch_valid = avg_losses_epoch_valid\n",
    "        else:\n",
    "            if min_loss_epoch_valid - avg_losses_epoch_valid > min_delta:\n",
    "                is_best_model = 1\n",
    "                best_model = model\n",
    "                min_loss_epoch_valid = avg_losses_epoch_valid \n",
    "                patient_epoch = 0\n",
    "            else:\n",
    "                is_best_model = 0\n",
    "                patient_epoch += 1\n",
    "                if patient_epoch >= patience:\n",
    "                    print('Early Stopped at Epoch:', epoch)\n",
    "                    break\n",
    "        \n",
    "        # Print training parameters\n",
    "        cur_time = time.time()\n",
    "        print('Epoch: {}, train_loss: {}, valid_loss: {}, time: {}, best model: {}'.format( \\\n",
    "                    epoch, \\\n",
    "                    np.around(avg_losses_epoch_train, decimals=8),\\\n",
    "                    np.around(avg_losses_epoch_valid, decimals=8),\\\n",
    "                    np.around([cur_time - pre_time] , decimals=2),\\\n",
    "                    is_best_model) )\n",
    "        pre_time = cur_time\n",
    "    return best_model, [losses_train, losses_valid, losses_epochs_train, losses_epochs_valid]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TestModel(model, test_dataloader, max_speed):\n",
    "    \n",
    "    inputs, labels = next(iter(test_dataloader))\n",
    "    [batch_size, step_size, fea_size] = inputs.size()\n",
    "\n",
    "    cur_time = time.time()\n",
    "    pre_time = time.time()\n",
    "    \n",
    "    use_gpu = torch.cuda.is_available()\n",
    "    \n",
    "    loss_MSE = torch.nn.MSELoss()\n",
    "    loss_L1 = torch.nn.MSELoss()\n",
    "    \n",
    "    tested_batch = 0\n",
    "    \n",
    "    losses_mse = []\n",
    "    losses_l1 = [] \n",
    "    MAPE = []\n",
    "    for data in test_dataloader:\n",
    "        \n",
    "        inputs, labels = data\n",
    "        \n",
    "        if inputs.shape[0] != batch_size:\n",
    "            continue\n",
    "    \n",
    "        if use_gpu:\n",
    "            inputs, labels = Variable(inputs.cuda()), Variable(labels.cuda())\n",
    "        else: \n",
    "            inputs, labels = Variable(inputs), Variable(labels)\n",
    "\n",
    "        # rnn.loop() \n",
    "        hidden = model.initHidden(batch_size)\n",
    "\n",
    "        outputs = None\n",
    "        outputs = model(inputs)\n",
    "        outputs_np = np.array(outputs.data.numpy())\n",
    "        \n",
    "        sqlabel = torch.squeeze(labels)\n",
    "        loss_MSE = torch.nn.MSELoss()\n",
    "        loss_L1 = torch.nn.L1Loss()\n",
    "        loss_mse = loss_MSE(outputs, sqlabel)\n",
    "        loss_l1 = loss_L1(outputs, sqlabel)\n",
    "        loss_MAPE = torch.mean(torch.abs(outputs[sqlabel != 0] - sqlabel[sqlabel != 0]) / sqlabel[sqlabel != 0])\n",
    "        \n",
    "        losses_mse.append(loss_mse.cpu().data.numpy())\n",
    "        losses_l1.append(loss_l1.cpu().data.numpy())\n",
    "        MAPE.append(loss_MAPE.cpu().data.numpy())\n",
    "        \n",
    "        tested_batch += 1\n",
    "    \n",
    "        if tested_batch % 1000 == 0:\n",
    "            cur_time = time.time()\n",
    "            print('Tested #: {}, loss_l1: {}, loss_mse: {}, time: {}'.format( \\\n",
    "                  tested_batch * batch_size, \\\n",
    "                  np.around([loss_l1.data[0]], decimals=8), \\\n",
    "                  np.around([loss_mse.data[0]], decimals=8), \\\n",
    "                  np.around([cur_time - pre_time], decimals=8) ) )\n",
    "            pre_time = cur_time\n",
    "    losses_l1 = np.array(losses_l1)\n",
    "    losses_mse = np.array(losses_mse)\n",
    "    MAPE = np.array(MAPE)\n",
    "    mean_l1 = np.mean(losses_l1) * max_speed\n",
    "    std_l1 = np.std(losses_l1) * max_speed\n",
    "    RMSE_ = np.sqrt(np.mean(losses_mse)) * max_speed\n",
    "    MAPE_ = np.mean(MAPE) * 100\n",
    "    print('Tested: L1_mean: {}, L1_std : {}, MAPE : {}, RMSE : {}'.format(mean_l1, std_l1, MAPE_, RMSE_))\n",
    "    return [losses_l1, losses_mse, mean_l1, std_l1, outputs_np]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "    def __init__(self, input_size, cell_size, hidden_size, output_last = True):\n",
    "        \"\"\"\n",
    "        cell_size is the size of cell_state.\n",
    "        hidden_size is the size of hidden_state, or say the output_state of each step\n",
    "        \"\"\"\n",
    "        super(LSTM, self).__init__()\n",
    "        \n",
    "        self.cell_size = cell_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.fl = nn.Linear(input_size + hidden_size, hidden_size)\n",
    "        self.il = nn.Linear(input_size + hidden_size, hidden_size)\n",
    "        self.ol = nn.Linear(input_size + hidden_size, hidden_size)\n",
    "        self.Cl = nn.Linear(input_size + hidden_size, hidden_size)\n",
    "        \n",
    "        self.output_last = output_last\n",
    "        \n",
    "    def step(self, input, Hidden_State, Cell_State):\n",
    "        combined = torch.cat((input, Hidden_State), 1)\n",
    "        f = F.sigmoid(self.fl(combined))\n",
    "        i = F.sigmoid(self.il(combined))\n",
    "        o = F.sigmoid(self.ol(combined))\n",
    "        C = F.tanh(self.Cl(combined))\n",
    "        Cell_State = f * Cell_State + i * C\n",
    "        Hidden_State = o * F.tanh(Cell_State)\n",
    "        \n",
    "        return Hidden_State, Cell_State\n",
    "    \n",
    "    def forward(self, inputs):\n",
    "        batch_size = inputs.size(0)\n",
    "        time_step = inputs.size(1)\n",
    "        Hidden_State, Cell_State = self.initHidden(batch_size)\n",
    "        \n",
    "        if self.output_last:\n",
    "            for i in range(time_step):\n",
    "                Hidden_State, Cell_State = self.step(torch.squeeze(inputs[:,i:i+1,:]), Hidden_State, Cell_State)  \n",
    "            return Hidden_State\n",
    "        else:\n",
    "            outputs = None\n",
    "            for i in range(time_step):\n",
    "                Hidden_State, Cell_State = self.step(torch.squeeze(inputs[:,i:i+1,:]), Hidden_State, Cell_State)  \n",
    "                if outputs is None:\n",
    "                    outputs = Hidden_State.unsqueeze(1)\n",
    "                else:\n",
    "                    outputs = torch.cat((outputs, Hidden_State.unsqueeze(1)), 1)\n",
    "            return outputs\n",
    "    \n",
    "    def initHidden(self, batch_size):\n",
    "        use_gpu = torch.cuda.is_available()\n",
    "        if use_gpu:\n",
    "            Hidden_State = Variable(torch.zeros(batch_size, self.hidden_size).cuda())\n",
    "            Cell_State = Variable(torch.zeros(batch_size, self.hidden_size).cuda())\n",
    "            return Hidden_State, Cell_State\n",
    "        else:\n",
    "            Hidden_State = Variable(torch.zeros(batch_size, self.hidden_size))\n",
    "            Cell_State = Variable(torch.zeros(batch_size, self.hidden_size))\n",
    "            return Hidden_State, Cell_State\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvLSTM(nn.Module):\n",
    "    def __init__(self, input_size, cell_size, hidden_size, output_last = True):\n",
    "        \"\"\"\n",
    "        cell_size is the size of cell_state.\n",
    "        hidden_size is the size of hidden_state, or say the output_state of each step\n",
    "        \"\"\"\n",
    "        super(ConvLSTM, self).__init__()\n",
    "        \n",
    "        self.cell_size = cell_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.fl = nn.Linear(input_size + hidden_size, hidden_size)\n",
    "        self.il = nn.Linear(input_size + hidden_size, hidden_size)\n",
    "        self.ol = nn.Linear(input_size + hidden_size, hidden_size)\n",
    "        self.Cl = nn.Linear(input_size + hidden_size, hidden_size)\n",
    "        \n",
    "        self.conv = nn.Conv1d(1, hidden_size, hidden_size)\n",
    "        \n",
    "        self.output_last = output_last\n",
    "        \n",
    "    def step(self, input, Hidden_State, Cell_State):\n",
    "        \n",
    "        conv = self.conv(input)\n",
    "        \n",
    "        combined = torch.cat((conv, Hidden_State), 1)\n",
    "        f = F.sigmoid(self.fl(combined))\n",
    "        i = F.sigmoid(self.il(combined))\n",
    "        o = F.sigmoid(self.ol(combined))\n",
    "        C = F.tanh(self.Cl(combined))\n",
    "        Cell_State = f * Cell_State + i * C\n",
    "        Hidden_State = o * F.tanh(Cell_State)\n",
    "        \n",
    "        return Hidden_State, Cell_State\n",
    "    \n",
    "    def forward(self, inputs):\n",
    "        batch_size = inputs.size(0)\n",
    "        time_step = inputs.size(1)\n",
    "        Hidden_State, Cell_State = self.initHidden(batch_size)\n",
    "        \n",
    "        if self.output_last:\n",
    "            for i in range(time_step):\n",
    "                Hidden_State, Cell_State = self.step(torch.squeeze(inputs[:,i:i+1,:]), Hidden_State, Cell_State)  \n",
    "            return Hidden_State\n",
    "        else:\n",
    "            outputs = None\n",
    "            for i in range(time_step):\n",
    "                Hidden_State, Cell_State = self.step(torch.squeeze(inputs[:,i:i+1,:]), Hidden_State, Cell_State)  \n",
    "                if outputs is None:\n",
    "                    outputs = Hidden_State.unsqueeze(1)\n",
    "                else:\n",
    "                    outputs = torch.cat((outputs, Hidden_State.unsqueeze(1)), 1)\n",
    "            return outputs\n",
    "    \n",
    "    def initHidden(self, batch_size):\n",
    "        use_gpu = torch.cuda.is_available()\n",
    "        if use_gpu:\n",
    "            Hidden_State = Variable(torch.zeros(batch_size, self.hidden_size).cuda())\n",
    "            Cell_State = Variable(torch.zeros(batch_size, self.hidden_size).cuda())\n",
    "            return Hidden_State, Cell_State\n",
    "        else:\n",
    "            Hidden_State = Variable(torch.zeros(batch_size, self.hidden_size))\n",
    "            Cell_State = Variable(torch.zeros(batch_size, self.hidden_size))\n",
    "            return Hidden_State, Cell_State\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LocalizedSpectralGraphConvolution(nn.Module):\n",
    "    def __init__(self, A, K):\n",
    "        \n",
    "        super(LocalizedSpectralGraphConvolution, self).__init__()\n",
    "        \n",
    "        \n",
    "        self.K = K\n",
    "#         self.A = A.cuda()\n",
    "        self.A = A\n",
    "        feature_size = A.shape[0]\n",
    "#         self.D = torch.diag(torch.sum(self.A, dim=0)).cuda()\n",
    "        self.D = torch.diag(torch.sum(self.A, dim=0))\n",
    "    \n",
    "#         I = torch.eye(feature_size,feature_size).cuda()\n",
    "        I = torch.eye(feature_size,feature_size)\n",
    "        self.L = I - torch.inverse(torch.sqrt(self.D)).matmul(self.A).matmul(torch.inverse(torch.sqrt(self.D))) \n",
    "        \n",
    "        L_temp = I\n",
    "        for i in range(K):\n",
    "            L_temp = torch.matmul(L_temp, self.L)\n",
    "            if i == 0:\n",
    "                self.L_tensor = torch.unsqueeze(L_temp, 2)\n",
    "            else:\n",
    "                self.L_tensor = torch.cat((self.L_tensor, torch.unsqueeze(L_temp, 2)), 2)\n",
    "            \n",
    "#         self.L_tensor = Variable(self.L_tensor.cuda(), requires_grad=False)\n",
    "        self.L_tensor = Variable(self.L_tensor, requires_grad=False)\n",
    "#         self.params = Parameter(torch.FloatTensor(K).cuda())\n",
    "        self.params = Parameter(torch.FloatTensor(K))\n",
    "        \n",
    "        stdv = 1. / math.sqrt(K)\n",
    "        for i in range(K):\n",
    "            self.params[i].data.uniform_(-stdv, stdv)\n",
    "\n",
    "    def forward(self, input):\n",
    "        x = input\n",
    "\n",
    "        conv = x.matmul( torch.sum(self.params.expand_as(self.L_tensor) * self.L_tensor, 2) )\n",
    "\n",
    "        return conv\n",
    "        \n",
    "        \n",
    "class LocalizedSpectralGraphConvolutionalLSTM(nn.Module):\n",
    "    \n",
    "    def __init__(self, K, A, feature_size, Clamp_A=True, output_last = True):\n",
    "        '''\n",
    "        Args:\n",
    "            K: K-hop graph\n",
    "            A: adjacency matrix\n",
    "            FFR: free-flow reachability matrix\n",
    "            feature_size: the dimension of features\n",
    "            Clamp_A: Boolean value, clamping all elements of A between 0. to 1.\n",
    "        '''\n",
    "        super(LocalizedSpectralGraphConvolutionalLSTM, self).__init__()\n",
    "        self.feature_size = feature_size\n",
    "        self.hidden_size = feature_size\n",
    "        \n",
    "        self.K = K\n",
    "        self.A = A\n",
    "        self.gconv = LocalizedSpectralGraphConvolution(A, K)\n",
    "    \n",
    "        hidden_size = self.feature_size\n",
    "        input_size = self.feature_size + hidden_size\n",
    "\n",
    "        self.fl = nn.Linear(input_size, hidden_size)\n",
    "        self.il = nn.Linear(input_size, hidden_size)\n",
    "        self.ol = nn.Linear(input_size, hidden_size)\n",
    "        self.Cl = nn.Linear(input_size, hidden_size)\n",
    "        \n",
    "        self.output_last = output_last\n",
    "        \n",
    "    def step(self, input, Hidden_State, Cell_State):\n",
    "        \n",
    "#         conv_sample_start = time.time()  \n",
    "        conv = F.relu(self.gconv(input))\n",
    "#         conv_sample_end = time.time()  \n",
    "#         print('conv_sample:', (conv_sample_end - conv_sample_start))\n",
    "        combined = torch.cat((conv, Hidden_State), 1)\n",
    "        f = F.sigmoid(self.fl(combined))\n",
    "        i = F.sigmoid(self.il(combined))\n",
    "        o = F.sigmoid(self.ol(combined))\n",
    "        C = F.tanh(self.Cl(combined))\n",
    "        Cell_State = f * Cell_State + i * C\n",
    "        Hidden_State = o * F.tanh(Cell_State)\n",
    "        \n",
    "        return Hidden_State, Cell_State\n",
    "    \n",
    "    def Bi_torch(self, a):\n",
    "        a[a < 0] = 0\n",
    "        a[a > 0] = 1\n",
    "        return a\n",
    "    \n",
    "    def forward(self, inputs):\n",
    "        batch_size = inputs.size(0)\n",
    "        time_step = inputs.size(1)\n",
    "        Hidden_State, Cell_State = self.initHidden(batch_size)\n",
    "        \n",
    "        outputs = None\n",
    "        \n",
    "        for i in range(time_step):\n",
    "            Hidden_State, Cell_State = self.step(torch.squeeze(inputs[:,i:i+1,:]), Hidden_State, Cell_State)  \n",
    "\n",
    "            if outputs is None:\n",
    "                outputs = Hidden_State.unsqueeze(1)\n",
    "            else:\n",
    "                outputs = torch.cat((outputs, Hidden_State.unsqueeze(1)), 1)\n",
    "#         print(type(outputs))\n",
    "        \n",
    "        if self.output_last:\n",
    "            return outputs[:,-1,:]\n",
    "        else:\n",
    "            return outputs\n",
    "    \n",
    "    def initHidden(self, batch_size):\n",
    "        use_gpu = torch.cuda.is_available()\n",
    "        if use_gpu:\n",
    "            Hidden_State = Variable(torch.zeros(batch_size, self.hidden_size).cuda())\n",
    "            Cell_State = Variable(torch.zeros(batch_size, self.hidden_size).cuda())\n",
    "            return Hidden_State, Cell_State\n",
    "        else:\n",
    "            Hidden_State = Variable(torch.zeros(batch_size, self.hidden_size))\n",
    "            Cell_State = Variable(torch.zeros(batch_size, self.hidden_size))\n",
    "            return Hidden_State, Cell_State\n",
    "    def reinitHidden(self, batch_size, Hidden_State_data, Cell_State_data):\n",
    "        use_gpu = torch.cuda.is_available()\n",
    "        if use_gpu:\n",
    "            Hidden_State = Variable(Hidden_State_data.cuda(), requires_grad=True)\n",
    "            Cell_State = Variable(Cell_State_data.cuda(), requires_grad=True)\n",
    "            return Hidden_State, Cell_State\n",
    "        else:\n",
    "            Hidden_State = Variable(Hidden_State_data, requires_grad=True)\n",
    "            Cell_State = Variable(Cell_State_data, requires_grad=True)\n",
    "            return Hidden_State, Cell_State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpectralGraphConvolution(nn.Module):\n",
    "    def __init__(self, A):\n",
    "        \n",
    "        super(SpectralGraphConvolution, self).__init__()\n",
    "        \n",
    "        feature_size = A.shape[0]\n",
    "        \n",
    "        self.A = A\n",
    "        self.D = torch.diag(torch.sum(self.A, dim=0))\n",
    "        self.L = self.D - A\n",
    "#         self.param = Parameter(torch.FloatTensor(feature_size).cuda())\n",
    "        self.param = Parameter(torch.FloatTensor(feature_size))\n",
    "        stdv = 1. / math.sqrt(feature_size)\n",
    "        self.param.data.uniform_(-stdv, stdv)\n",
    "        \n",
    "        self.e, self.v = torch.eig(self.L, eigenvectors=True)\n",
    "        self.vt = torch.t(self.v)\n",
    "#         self.v = Variable(self.v.cuda(), requires_grad=False)\n",
    "#         self.vt = Variable(self.vt.cuda(), requires_grad=False)\n",
    "        self.v = Variable(self.v, requires_grad=False)\n",
    "        self.vt = Variable(self.vt, requires_grad=False)\n",
    "        \n",
    "    def forward(self, input):\n",
    "        x = input\n",
    "        conv_sample_start = time.time()  \n",
    "        conv = x.matmul(self.v.matmul(torch.diag(self.param)).matmul(self.vt))\n",
    "        conv_sample_end = time.time()  \n",
    "        #print('conv_sample:', (conv_sample_end - conv_sample_start))\n",
    "        return conv\n",
    "        \n",
    "class SpectralGraphConvolutionalLSTM(nn.Module):\n",
    "    \n",
    "    def __init__(self, K, A, feature_size, Clamp_A=True, output_last = True):\n",
    "        '''\n",
    "        Args:\n",
    "            K: K-hop graph\n",
    "            A: adjacency matrix\n",
    "            FFR: free-flow reachability matrix\n",
    "            feature_size: the dimension of features\n",
    "            Clamp_A: Boolean value, clamping all elements of A between 0. to 1.\n",
    "        '''\n",
    "        super(SpectralGraphConvolutionalLSTM, self).__init__()\n",
    "        self.feature_size = feature_size\n",
    "        self.hidden_size = feature_size\n",
    "        \n",
    "        self.K = K\n",
    "        self.A = A\n",
    "        self.gconv = SpectralGraphConvolution(A)\n",
    "    \n",
    "        hidden_size = self.feature_size\n",
    "        input_size = self.feature_size + hidden_size\n",
    "\n",
    "        self.fl = nn.Linear(input_size, hidden_size)\n",
    "        self.il = nn.Linear(input_size, hidden_size)\n",
    "        self.ol = nn.Linear(input_size, hidden_size)\n",
    "        self.Cl = nn.Linear(input_size, hidden_size)\n",
    "        \n",
    "        self.output_last = output_last\n",
    "        \n",
    "    def step(self, input, Hidden_State, Cell_State):\n",
    "        conv_sample_start = time.time()  \n",
    "        conv = self.gconv(input)\n",
    "        conv_sample_end = time.time()  \n",
    "        #print('conv_sample:', (conv_sample_end - conv_sample_start))\n",
    "        combined = torch.cat((conv, Hidden_State), 1)\n",
    "        f = F.sigmoid(self.fl(combined))\n",
    "        i = F.sigmoid(self.il(combined))\n",
    "        o = F.sigmoid(self.ol(combined))\n",
    "        C = F.tanh(self.Cl(combined))\n",
    "        Cell_State = f * Cell_State + i * C\n",
    "        Hidden_State = o * F.tanh(Cell_State)\n",
    "        \n",
    "        return Hidden_State, Cell_State\n",
    "    \n",
    "    def Bi_torch(self, a):\n",
    "        a[a < 0] = 0\n",
    "        a[a > 0] = 1\n",
    "        return a\n",
    "    \n",
    "    def forward(self, inputs):\n",
    "        batch_size = inputs.size(0)\n",
    "        time_step = inputs.size(1)\n",
    "        Hidden_State, Cell_State = self.initHidden(batch_size)\n",
    "        \n",
    "        outputs = None\n",
    "        \n",
    "        train_sample_start = time.time()  \n",
    "        \n",
    "        for i in range(time_step):\n",
    "            Hidden_State, Cell_State = self.step(torch.squeeze(inputs[:,i:i+1,:]), Hidden_State, Cell_State)  \n",
    "\n",
    "            if outputs is None:\n",
    "                outputs = Hidden_State.unsqueeze(1)\n",
    "            else:\n",
    "                outputs = torch.cat((outputs, Hidden_State.unsqueeze(1)), 1)\n",
    "        \n",
    "        train_sample_end = time.time()\n",
    "        #print('train sample:' , (train_sample_end - train_sample_start))\n",
    "        if self.output_last:\n",
    "            return outputs[:,-1,:]\n",
    "        else:\n",
    "            return outputs\n",
    "    \n",
    "    def initHidden(self, batch_size):\n",
    "        use_gpu = torch.cuda.is_available()\n",
    "        if use_gpu:\n",
    "            Hidden_State = Variable(torch.zeros(batch_size, self.hidden_size).cuda())\n",
    "            Cell_State = Variable(torch.zeros(batch_size, self.hidden_size).cuda())\n",
    "            return Hidden_State, Cell_State\n",
    "        else:\n",
    "            Hidden_State = Variable(torch.zeros(batch_size, self.hidden_size))\n",
    "            Cell_State = Variable(torch.zeros(batch_size, self.hidden_size))\n",
    "            return Hidden_State, Cell_State\n",
    "    def reinitHidden(self, batch_size, Hidden_State_data, Cell_State_data):\n",
    "        use_gpu = torch.cuda.is_available()\n",
    "        if use_gpu:\n",
    "            Hidden_State = Variable(Hidden_State_data.cuda(), requires_grad=True)\n",
    "            Cell_State = Variable(Cell_State_data.cuda(), requires_grad=True)\n",
    "            return Hidden_State, Cell_State\n",
    "        else:\n",
    "            Hidden_State = Variable(Hidden_State_data, requires_grad=True)\n",
    "            Cell_State = Variable(Cell_State_data, requires_grad=True)\n",
    "            return Hidden_State, Cell_State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FilterLinear(nn.Module):\n",
    "    def __init__(self, in_features, out_features, filter_square_matrix, bias=True):\n",
    "        '''\n",
    "        filter_square_matrix : filter square matrix, whose each elements is 0 or 1.\n",
    "        '''\n",
    "        super(FilterLinear, self).__init__()\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        \n",
    "        use_gpu = torch.cuda.is_available()\n",
    "        self.filter_square_matrix = None\n",
    "        if use_gpu:\n",
    "            self.filter_square_matrix = Variable(filter_square_matrix.cuda(), requires_grad=False)\n",
    "        else:\n",
    "            self.filter_square_matrix = Variable(filter_square_matrix, requires_grad=False)\n",
    "        \n",
    "        self.weight = Parameter(torch.Tensor(out_features, in_features))\n",
    "        if bias:\n",
    "            self.bias = Parameter(torch.Tensor(out_features))\n",
    "        else:\n",
    "            self.register_parameter('bias', None)\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        stdv = 1. / math.sqrt(self.weight.size(1))\n",
    "        self.weight.data.uniform_(-stdv, stdv)\n",
    "        if self.bias is not None:\n",
    "            self.bias.data.uniform_(-stdv, stdv)\n",
    "#         print(self.weight.data)\n",
    "#         print(self.bias.data)\n",
    "\n",
    "    def forward(self, input):\n",
    "        return F.linear(input, self.filter_square_matrix.matmul(self.weight), self.bias)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return self.__class__.__name__ + '(' \\\n",
    "            + 'in_features=' + str(self.in_features) \\\n",
    "            + ', out_features=' + str(self.out_features) \\\n",
    "            + ', bias=' + str(self.bias is not None) + ')'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphConvolutionalLSTM(nn.Module):\n",
    "    \n",
    "    def __init__(self, K, A, FFR, feature_size, Clamp_A=True, output_last = True):\n",
    "        '''\n",
    "        Args:\n",
    "            K: K-hop graph\n",
    "            A: adjacency matrix\n",
    "            FFR: free-flow reachability matrix\n",
    "            feature_size: the dimension of features\n",
    "            Clamp_A: Boolean value, clamping all elements of A between 0. to 1.\n",
    "        '''\n",
    "        super(GraphConvolutionalLSTM, self).__init__()\n",
    "        self.feature_size = feature_size\n",
    "        self.hidden_size = feature_size\n",
    "        \n",
    "        self.K = K\n",
    "        \n",
    "        self.A_list = [] # Adjacency Matrix List\n",
    "        A = torch.FloatTensor(A)\n",
    "        A_temp = torch.eye(feature_size,feature_size)\n",
    "        for i in range(K):\n",
    "            A_temp = torch.matmul(A_temp, torch.Tensor(A))\n",
    "            if Clamp_A:\n",
    "                # confine elements of A \n",
    "                A_temp = torch.clamp(A_temp, max = 1.) \n",
    "            self.A_list.append(torch.mul(A_temp, torch.Tensor(FFR)))\n",
    "#             self.A_list.append(A_temp)\n",
    "        \n",
    "        # a length adjustable Module List for hosting all graph convolutions\n",
    "        self.gc_list = nn.ModuleList([FilterLinear(feature_size, feature_size, self.A_list[i], bias=False) for i in range(K)])                  \n",
    "        \n",
    "        hidden_size = self.feature_size\n",
    "        input_size = self.feature_size * K\n",
    "\n",
    "        self.fl = nn.Linear(input_size + hidden_size, hidden_size)\n",
    "        self.il = nn.Linear(input_size + hidden_size, hidden_size)\n",
    "        self.ol = nn.Linear(input_size + hidden_size, hidden_size)\n",
    "        self.Cl = nn.Linear(input_size + hidden_size, hidden_size)\n",
    "        \n",
    "        # initialize the neighbor weight for the cell state\n",
    "        self.Neighbor_weight = Parameter(torch.FloatTensor(feature_size))\n",
    "        stdv = 1. / math.sqrt(feature_size)\n",
    "        self.Neighbor_weight.data.uniform_(-stdv, stdv)\n",
    "        \n",
    "        self.output_last = output_last\n",
    "        \n",
    "    def step(self, input, Hidden_State, Cell_State):\n",
    "        \n",
    "        x = input\n",
    "\n",
    "        gc = self.gc_list[0](x)\n",
    "        for i in range(1, self.K):\n",
    "            gc = torch.cat((gc, self.gc_list[i](x)), 1)\n",
    "            \n",
    "        combined = torch.cat((gc, Hidden_State), 1)\n",
    "        f = F.sigmoid(self.fl(combined))\n",
    "        i = F.sigmoid(self.il(combined))\n",
    "        o = F.sigmoid(self.ol(combined))\n",
    "        C = F.tanh(self.Cl(combined))\n",
    "\n",
    "#         NC = torch.mul(Cell_State,  torch.mv(Variable(self.A_list[-1], requires_grad=False).cuda(), self.Neighbor_weight))\n",
    "        NC = torch.mul(Cell_State,  torch.mv(Variable(self.A_list[-1], requires_grad=False), self.Neighbor_weight))\n",
    "        Cell_State = f * NC + i * C\n",
    "        Hidden_State = o * F.tanh(Cell_State)\n",
    "\n",
    "        return Hidden_State, Cell_State, gc\n",
    "    \n",
    "    def Bi_torch(self, a):\n",
    "        a[a < 0] = 0\n",
    "        a[a > 0] = 1\n",
    "        return a\n",
    "    \n",
    "    def forward(self, inputs):\n",
    "        batch_size = inputs.size(0)\n",
    "        time_step = inputs.size(1)\n",
    "        Hidden_State, Cell_State = self.initHidden(batch_size)\n",
    "        \n",
    "        outputs = None\n",
    "        \n",
    "        for i in range(time_step):\n",
    "            Hidden_State, Cell_State, gc = self.step(torch.squeeze(inputs[:,i:i+1,:]), Hidden_State, Cell_State)  \n",
    "\n",
    "            if outputs is None:\n",
    "                outputs = Hidden_State.unsqueeze(1)\n",
    "            else:\n",
    "                outputs = torch.cat((outputs, Hidden_State.unsqueeze(1)), 1)\n",
    "        \n",
    "        if self.output_last:\n",
    "            return outputs[:,-1,:]\n",
    "        else:\n",
    "            return outputs\n",
    "    \n",
    "    def initHidden(self, batch_size):\n",
    "        use_gpu = torch.cuda.is_available()\n",
    "        if use_gpu:\n",
    "            Hidden_State = Variable(torch.zeros(batch_size, self.hidden_size).cuda())\n",
    "            Cell_State = Variable(torch.zeros(batch_size, self.hidden_size).cuda())\n",
    "            return Hidden_State, Cell_State\n",
    "        else:\n",
    "            Hidden_State = Variable(torch.zeros(batch_size, self.hidden_size))\n",
    "            Cell_State = Variable(torch.zeros(batch_size, self.hidden_size))\n",
    "            return Hidden_State, Cell_State\n",
    "    def reinitHidden(self, batch_size, Hidden_State_data, Cell_State_data):\n",
    "        use_gpu = torch.cuda.is_available()\n",
    "        if use_gpu:\n",
    "            Hidden_State = Variable(Hidden_State_data.cuda(), requires_grad=True)\n",
    "            Cell_State = Variable(Cell_State_data.cuda(), requires_grad=True)\n",
    "            return Hidden_State, Cell_State\n",
    "        else:\n",
    "            Hidden_State = Variable(Hidden_State_data, requires_grad=True)\n",
    "            Cell_State = Variable(Cell_State_data, requires_grad=True)\n",
    "            return Hidden_State, Cell_State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape:\n",
      "(323, 17568)\n",
      "\n",
      "Test_set shape:\n",
      "torch.Size([1441, 3, 323])\n"
     ]
    }
   ],
   "source": [
    "directory = '../datasets/Seattle_loop-data-set/'\n",
    "A = np.load( directory + 'Loop_Seattle_2015_A.npy')\n",
    "FFR_5min = np.load( directory + 'Loop_Seattle_2015_reachability_free_flow_5min.npy')\n",
    "FFR_10min = np.load( directory + 'Loop_Seattle_2015_reachability_free_flow_10min.npy')\n",
    "FFR_15min = np.load( directory + 'Loop_Seattle_2015_reachability_free_flow_15min.npy')\n",
    "FFR_20min = np.load( directory + 'Loop_Seattle_2015_reachability_free_flow_20min.npy')\n",
    "FFR_25min = np.load( directory + 'Loop_Seattle_2015_reachability_free_flow_25min.npy')\n",
    "FFR = [FFR_5min, FFR_10min, FFR_15min, FFR_20min, FFR_25min]\n",
    "\n",
    "directory = '../datasets/Seattle_loop-data-set/'\n",
    "A = np.load( directory + 'Loop_Seattle_2015_A.npy')\n",
    "dense_mat = np.load( directory + 'dense_mat.npy')\n",
    "\n",
    "print('Dataset shape:')\n",
    "print(dense_mat.shape)\n",
    "\n",
    "missing_rate = 0.4\n",
    "# =============================================================================\n",
    "### Random missing (PM) scenario\n",
    "### Set the PM scenario by:\n",
    "# rm_random_mat = np.load(directory + 'rm_random_mat.npy')\n",
    "# binary_mat = np.round(rm_random_mat + 0.5 - missing_rate)\n",
    "# =============================================================================\n",
    "# =============================================================================\n",
    "### Non-random missing (CM) scenario\n",
    "### Set the CM scenario by:\n",
    "nm_random_mat = np.load(directory + 'nm_random_mat.npy')\n",
    "binary_tensor = np.zeros((dense_mat.shape[0], 61, 288))\n",
    "for i1 in range(binary_tensor.shape[0]):\n",
    "    for i2 in range(binary_tensor.shape[1]):\n",
    "        binary_tensor[i1, i2, :] = np.round(nm_random_mat[i1, i2] + 0.5 - missing_rate)\n",
    "binary_mat = binary_tensor.reshape([binary_tensor.shape[0], binary_tensor.shape[1] * binary_tensor.shape[2]])\n",
    "# =============================================================================\n",
    "\n",
    "sparse_mat = np.multiply(dense_mat, binary_mat)\n",
    "sparse_mat = sparse_mat.T\n",
    "dense_mat = dense_mat.T\n",
    "\n",
    "time_lags = np.array([1, 2, 288])\n",
    "# time_lags = np.arange(1, 11, 1)\n",
    "\n",
    "train_dataloader, valid_dataloader, test_dataloader, max_speed = PrepareDataset(sparse_mat, dense_mat, BATCH_SIZE = 100, time_lags = time_lags, pred_len = 1, valid_len = 2882, test_len = 1441)\n",
    "\n",
    "inputs, labels = next(iter(train_dataloader))\n",
    "[batch_size, step_size, fea_size] = inputs.size()\n",
    "input_dim = fea_size\n",
    "hidden_dim = 60\n",
    "output_dim = fea_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, train_loss: 0.3339574337005615, valid_loss: 0.35196104645729065, time: [4.46], best model: 1\n",
      "Epoch: 1, train_loss: 0.12868650257587433, valid_loss: 0.13059088587760925, time: [4.39], best model: 1\n",
      "Epoch: 2, train_loss: 0.045536261051893234, valid_loss: 0.043487418442964554, time: [4.49], best model: 1\n",
      "Epoch: 3, train_loss: 0.02455797977745533, valid_loss: 0.021918289363384247, time: [4.61], best model: 1\n",
      "Epoch: 4, train_loss: 0.019868889823555946, valid_loss: 0.017253689467906952, time: [4.64], best model: 1\n",
      "Epoch: 5, train_loss: 0.018493790179491043, valid_loss: 0.016020409762859344, time: [4.75], best model: 1\n",
      "Epoch: 6, train_loss: 0.017773659899830818, valid_loss: 0.015560319647192955, time: [4.79], best model: 1\n",
      "Epoch: 7, train_loss: 0.017115440219640732, valid_loss: 0.014991720207035542, time: [4.81], best model: 1\n",
      "Epoch: 8, train_loss: 0.016383999958634377, valid_loss: 0.014761759899556637, time: [4.84], best model: 1\n",
      "Epoch: 9, train_loss: 0.015625, valid_loss: 0.014461490325629711, time: [4.84], best model: 1\n",
      "Epoch: 10, train_loss: 0.0149357495829463, valid_loss: 0.014024009928107262, time: [4.88], best model: 1\n",
      "Epoch: 11, train_loss: 0.014262090437114239, valid_loss: 0.013656959868967533, time: [4.87], best model: 1\n",
      "Epoch: 12, train_loss: 0.013637719675898552, valid_loss: 0.013360809534788132, time: [4.93], best model: 1\n",
      "Epoch: 13, train_loss: 0.013050509616732597, valid_loss: 0.013015789911150932, time: [4.95], best model: 1\n",
      "Epoch: 14, train_loss: 0.01250304002314806, valid_loss: 0.01277817040681839, time: [5.02], best model: 1\n",
      "Epoch: 15, train_loss: 0.011994170024991035, valid_loss: 0.012438270263373852, time: [5.], best model: 1\n",
      "Epoch: 16, train_loss: 0.011515960097312927, valid_loss: 0.01224237959831953, time: [4.96], best model: 1\n",
      "Epoch: 17, train_loss: 0.0111074298620224, valid_loss: 0.011979689821600914, time: [5.04], best model: 1\n",
      "Epoch: 18, train_loss: 0.0107107600197196, valid_loss: 0.011746100150048733, time: [5.], best model: 1\n",
      "Epoch: 19, train_loss: 0.010366279631853104, valid_loss: 0.011548769660294056, time: [5.04], best model: 1\n",
      "Epoch: 20, train_loss: 0.010051540099084377, valid_loss: 0.011384519748389721, time: [5.03], best model: 1\n",
      "Epoch: 21, train_loss: 0.009765209630131721, valid_loss: 0.011170639656484127, time: [5.09], best model: 1\n",
      "Epoch: 22, train_loss: 0.009494650177657604, valid_loss: 0.010990330018103123, time: [5.08], best model: 1\n",
      "Epoch: 23, train_loss: 0.0092580895870924, valid_loss: 0.010811259970068932, time: [5.07], best model: 1\n",
      "Epoch: 24, train_loss: 0.009024079889059067, valid_loss: 0.010641460306942463, time: [5.05], best model: 1\n",
      "Epoch: 25, train_loss: 0.008823609910905361, valid_loss: 0.010491680353879929, time: [5.07], best model: 1\n",
      "Epoch: 26, train_loss: 0.008629250340163708, valid_loss: 0.010374929755926132, time: [5.04], best model: 1\n",
      "Epoch: 27, train_loss: 0.008457000367343426, valid_loss: 0.010263640433549881, time: [5.04], best model: 1\n",
      "Epoch: 28, train_loss: 0.008298169821500778, valid_loss: 0.010170849971473217, time: [5.02], best model: 1\n",
      "Epoch: 29, train_loss: 0.008144959807395935, valid_loss: 0.010017620399594307, time: [5.07], best model: 1\n",
      "Epoch: 30, train_loss: 0.007996680215001106, valid_loss: 0.009954869747161865, time: [5.04], best model: 1\n",
      "Epoch: 31, train_loss: 0.007868790067732334, valid_loss: 0.009820439852774143, time: [5.06], best model: 1\n",
      "Epoch: 32, train_loss: 0.007748730015009642, valid_loss: 0.009754929691553116, time: [5.06], best model: 1\n",
      "Epoch: 33, train_loss: 0.007633650209754705, valid_loss: 0.009693319909274578, time: [5.1], best model: 1\n",
      "Epoch: 34, train_loss: 0.007529720198363066, valid_loss: 0.009631980210542679, time: [5.09], best model: 1\n",
      "Epoch: 35, train_loss: 0.007424579933285713, valid_loss: 0.009524759836494923, time: [5.79], best model: 1\n",
      "Epoch: 36, train_loss: 0.007332080043852329, valid_loss: 0.009477299638092518, time: [5.88], best model: 1\n",
      "Epoch: 37, train_loss: 0.007242240011692047, valid_loss: 0.009414340369403362, time: [6.08], best model: 1\n",
      "Epoch: 38, train_loss: 0.007161300163716078, valid_loss: 0.009381989948451519, time: [6.13], best model: 1\n",
      "Epoch: 39, train_loss: 0.007081440184265375, valid_loss: 0.009366540238261223, time: [6.29], best model: 1\n",
      "Epoch: 40, train_loss: 0.007004059851169586, valid_loss: 0.009293859824538231, time: [6.28], best model: 1\n",
      "Epoch: 41, train_loss: 0.006934939883649349, valid_loss: 0.00926921982318163, time: [6.24], best model: 1\n",
      "Epoch: 42, train_loss: 0.006868499796837568, valid_loss: 0.00922979973256588, time: [6.22], best model: 1\n",
      "Epoch: 43, train_loss: 0.00680510001257062, valid_loss: 0.009184439666569233, time: [6.29], best model: 1\n",
      "Epoch: 44, train_loss: 0.006750899832695723, valid_loss: 0.009180399589240551, time: [6.25], best model: 0\n",
      "Epoch: 45, train_loss: 0.006686709821224213, valid_loss: 0.0091186398640275, time: [6.24], best model: 1\n",
      "Epoch: 46, train_loss: 0.0066295200958848, valid_loss: 0.009104330092668533, time: [6.2], best model: 1\n",
      "Epoch: 47, train_loss: 0.0065710400231182575, valid_loss: 0.009108670055866241, time: [6.64], best model: 0\n",
      "Epoch: 48, train_loss: 0.006522450130432844, valid_loss: 0.00902354996651411, time: [6.29], best model: 1\n",
      "Epoch: 49, train_loss: 0.006475720088928938, valid_loss: 0.009029240347445011, time: [7.54], best model: 0\n",
      "Epoch: 50, train_loss: 0.00642857002094388, valid_loss: 0.00904737040400505, time: [6.34], best model: 0\n",
      "Epoch: 51, train_loss: 0.0063784001395106316, valid_loss: 0.009029019623994827, time: [6.43], best model: 0\n",
      "Epoch: 52, train_loss: 0.006336450111120939, valid_loss: 0.009006859734654427, time: [6.24], best model: 1\n",
      "Epoch: 53, train_loss: 0.006290200166404247, valid_loss: 0.008963909931480885, time: [6.19], best model: 1\n",
      "Epoch: 54, train_loss: 0.006249039899557829, valid_loss: 0.008973900228738785, time: [6.15], best model: 0\n",
      "Epoch: 55, train_loss: 0.0062118698842823505, valid_loss: 0.008965940214693546, time: [6.17], best model: 0\n",
      "Epoch: 56, train_loss: 0.00616980018094182, valid_loss: 0.008931459859013557, time: [5.98], best model: 1\n",
      "Epoch: 57, train_loss: 0.006132469978183508, valid_loss: 0.008933110162615776, time: [5.9], best model: 0\n",
      "Epoch: 58, train_loss: 0.006098079960793257, valid_loss: 0.00894481036812067, time: [5.75], best model: 0\n",
      "Epoch: 59, train_loss: 0.00606141984462738, valid_loss: 0.008919590152800083, time: [5.68], best model: 1\n",
      "Epoch: 60, train_loss: 0.0060299900360405445, valid_loss: 0.008951939642429352, time: [5.58], best model: 0\n",
      "Epoch: 61, train_loss: 0.005994049832224846, valid_loss: 0.008909139782190323, time: [5.46], best model: 1\n",
      "Epoch: 62, train_loss: 0.00595685001462698, valid_loss: 0.008945460431277752, time: [5.55], best model: 0\n",
      "Epoch: 63, train_loss: 0.00592833012342453, valid_loss: 0.008912909775972366, time: [5.38], best model: 0\n",
      "Epoch: 64, train_loss: 0.005902910139411688, valid_loss: 0.008899870328605175, time: [5.34], best model: 0\n",
      "Epoch: 65, train_loss: 0.005867610219866037, valid_loss: 0.008886720053851604, time: [5.39], best model: 1\n",
      "Epoch: 66, train_loss: 0.0058390898630023, valid_loss: 0.008866709657013416, time: [5.28], best model: 1\n",
      "Epoch: 67, train_loss: 0.005812330171465874, valid_loss: 0.008876319974660873, time: [5.27], best model: 0\n",
      "Epoch: 68, train_loss: 0.005783900152891874, valid_loss: 0.00888116005808115, time: [5.35], best model: 0\n",
      "Epoch: 69, train_loss: 0.005752529948949814, valid_loss: 0.008889609947800636, time: [5.28], best model: 0\n",
      "Epoch: 70, train_loss: 0.005723210051655769, valid_loss: 0.008852980099618435, time: [5.38], best model: 1\n",
      "Epoch: 71, train_loss: 0.005699839908629656, valid_loss: 0.008870059624314308, time: [5.46], best model: 0\n",
      "Epoch: 72, train_loss: 0.005676540080457926, valid_loss: 0.008864769712090492, time: [5.62], best model: 0\n",
      "Epoch: 73, train_loss: 0.005651239771395922, valid_loss: 0.008827020414173603, time: [5.7], best model: 1\n",
      "Epoch: 74, train_loss: 0.005625609774142504, valid_loss: 0.008861679583787918, time: [5.8], best model: 0\n",
      "Epoch: 75, train_loss: 0.005600019823759794, valid_loss: 0.008879199624061584, time: [5.84], best model: 0\n",
      "Epoch: 76, train_loss: 0.005573030095547438, valid_loss: 0.008857229724526405, time: [5.98], best model: 0\n",
      "Epoch: 77, train_loss: 0.005551939830183983, valid_loss: 0.00881929975003004, time: [6.18], best model: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 78, train_loss: 0.005529860034584999, valid_loss: 0.008864779956638813, time: [6.25], best model: 0\n",
      "Epoch: 79, train_loss: 0.0055082100443542, valid_loss: 0.008838980458676815, time: [6.25], best model: 0\n",
      "Epoch: 80, train_loss: 0.005485610105097294, valid_loss: 0.0088197598233819, time: [6.3], best model: 0\n",
      "Epoch: 81, train_loss: 0.005463730078190565, valid_loss: 0.00883105956017971, time: [6.29], best model: 0\n",
      "Epoch: 82, train_loss: 0.005444800015538931, valid_loss: 0.008852969855070114, time: [6.21], best model: 0\n",
      "Early Stopped at Epoch: 83\n",
      "Tested: L1_mean: 5.005535162566561, L1_std : 0.0, MAPE : 12.14158982038498, RMSE : 7.414167097375825\n"
     ]
    }
   ],
   "source": [
    "lstm = LSTM(input_dim, hidden_dim, output_dim, output_last = True)\n",
    "lstm, lstm_loss = TrainModel(lstm, train_dataloader, valid_dataloader, num_epochs = 200)\n",
    "lstm_test = TestModel(lstm, test_dataloader, max_speed )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, train_loss: 0.6803808212280273, valid_loss: 0.7129841446876526, time: [24.28], best model: 1\n",
      "Epoch: 1, train_loss: 0.6804695129394531, valid_loss: 0.7124403715133667, time: [22.89], best model: 1\n",
      "Epoch: 2, train_loss: 0.6800757646560669, valid_loss: 0.7127607464790344, time: [22.44], best model: 0\n",
      "Epoch: 3, train_loss: 0.6800888776779175, valid_loss: 0.7126150131225586, time: [22.88], best model: 0\n",
      "Epoch: 4, train_loss: 0.6800166964530945, valid_loss: 0.7125856280326843, time: [23.32], best model: 0\n",
      "Epoch: 5, train_loss: 0.6800587177276611, valid_loss: 0.7127432227134705, time: [25.03], best model: 0\n",
      "Epoch: 6, train_loss: 0.6801396012306213, valid_loss: 0.7125070691108704, time: [26.18], best model: 0\n",
      "Epoch: 7, train_loss: 0.6800600290298462, valid_loss: 0.7125433683395386, time: [27.15], best model: 0\n",
      "Epoch: 8, train_loss: 0.6800187230110168, valid_loss: 0.7129371762275696, time: [24.79], best model: 0\n",
      "Epoch: 9, train_loss: 0.6799517869949341, valid_loss: 0.7124120593070984, time: [22.93], best model: 1\n",
      "Epoch: 10, train_loss: 0.6800557374954224, valid_loss: 0.7122001647949219, time: [22.65], best model: 1\n",
      "Epoch: 11, train_loss: 0.6800398230552673, valid_loss: 0.7121150493621826, time: [22.99], best model: 1\n",
      "Epoch: 12, train_loss: 0.6799930930137634, valid_loss: 0.7127265334129333, time: [23.78], best model: 0\n",
      "Epoch: 13, train_loss: 0.6800060868263245, valid_loss: 0.7119061350822449, time: [25.47], best model: 1\n",
      "Epoch: 14, train_loss: 0.6799572706222534, valid_loss: 0.7129650115966797, time: [26.28], best model: 0\n",
      "Epoch: 15, train_loss: 0.6800249814987183, valid_loss: 0.712383508682251, time: [26.35], best model: 0\n",
      "Epoch: 16, train_loss: 0.6800816059112549, valid_loss: 0.7126469612121582, time: [24.99], best model: 0\n",
      "Epoch: 17, train_loss: 0.6800037622451782, valid_loss: 0.7122257351875305, time: [23.49], best model: 0\n",
      "Epoch: 18, train_loss: 0.6799601316452026, valid_loss: 0.7123228907585144, time: [22.58], best model: 0\n",
      "Epoch: 19, train_loss: 0.6799071431159973, valid_loss: 0.7127113342285156, time: [22.88], best model: 0\n",
      "Epoch: 20, train_loss: 0.679993748664856, valid_loss: 0.7119655013084412, time: [23.21], best model: 0\n",
      "Epoch: 21, train_loss: 0.6800848245620728, valid_loss: 0.7123775482177734, time: [23.21], best model: 0\n",
      "Epoch: 22, train_loss: 0.6799119710922241, valid_loss: 0.7123115062713623, time: [23.71], best model: 0\n",
      "Early Stopped at Epoch: 23\n",
      "Tested: L1_mean: 60.74127817111874, L1_std : 0.0, MAPE : 105.14527559280396, RMSE : 69.12573947579638\n"
     ]
    }
   ],
   "source": [
    "K = 64\n",
    "Clamp_A = False\n",
    "lsgclstm = LocalizedSpectralGraphConvolutionalLSTM(K, torch.Tensor(A), A.shape[0], Clamp_A=Clamp_A, output_last = True)\n",
    "lsgclstm, lsgclstm_loss = TrainModel(lsgclstm, train_dataloader, valid_dataloader, num_epochs = 200)\n",
    "lsgclstm_test = TestModel(lsgclstm, test_dataloader, max_speed )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 3\n",
    "back_length = 3\n",
    "Clamp_A = False\n",
    "sgclstm = SpectralGraphConvolutionalLSTM(K, torch.Tensor(A), A.shape[0], Clamp_A=Clamp_A, output_last = True)\n",
    "sgclstm, sgclstm_loss = TrainModel(sgclstm, train_dataloader, valid_dataloader, num_epochs = 200)\n",
    "sgclstm_test = TestModel(sgclstm, test_dataloader, max_speed )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, train_loss: 0.13212086260318756, valid_loss: 0.13522964715957642, time: [10.59], best model: 1\n",
      "Epoch: 1, train_loss: 0.041993398219347, valid_loss: 0.0428180918097496, time: [11.53], best model: 1\n",
      "Epoch: 2, train_loss: 0.027062859386205673, valid_loss: 0.027360010892152786, time: [12.14], best model: 1\n",
      "Epoch: 3, train_loss: 0.019733069464564323, valid_loss: 0.020925279706716537, time: [12.46], best model: 1\n",
      "Epoch: 4, train_loss: 0.01488890964537859, valid_loss: 0.016917500644922256, time: [13.81], best model: 1\n",
      "Epoch: 5, train_loss: 0.012853049673140049, valid_loss: 0.01569673977792263, time: [13.48], best model: 1\n",
      "Epoch: 6, train_loss: 0.010094859637320042, valid_loss: 0.013394540175795555, time: [12.19], best model: 1\n",
      "Epoch: 7, train_loss: 0.009070070460438728, valid_loss: 0.01281294971704483, time: [12.54], best model: 1\n",
      "Epoch: 8, train_loss: 0.00839305017143488, valid_loss: 0.012489289976656437, time: [12.91], best model: 1\n",
      "Epoch: 9, train_loss: 0.007891490124166012, valid_loss: 0.012208729982376099, time: [12.88], best model: 1\n",
      "Epoch: 10, train_loss: 0.0074950698763132095, valid_loss: 0.012109819799661636, time: [12.82], best model: 1\n",
      "Epoch: 11, train_loss: 0.007175679784268141, valid_loss: 0.011999409645795822, time: [13.16], best model: 1\n",
      "Epoch: 12, train_loss: 0.006904520094394684, valid_loss: 0.011946669779717922, time: [12.78], best model: 1\n",
      "Epoch: 13, train_loss: 0.006674829870462418, valid_loss: 0.011961270123720169, time: [13.5], best model: 0\n",
      "Epoch: 14, train_loss: 0.00647370982915163, valid_loss: 0.01194021012634039, time: [13.05], best model: 0\n",
      "Epoch: 15, train_loss: 0.006296820007264614, valid_loss: 0.011967149563133717, time: [12.8], best model: 0\n",
      "Epoch: 16, train_loss: 0.006134849973022938, valid_loss: 0.011962720192968845, time: [12.79], best model: 0\n",
      "Epoch: 17, train_loss: 0.005997309926897287, valid_loss: 0.011999939568340778, time: [12.73], best model: 0\n",
      "Epoch: 18, train_loss: 0.005871629808098078, valid_loss: 0.012015829794108868, time: [13.17], best model: 0\n",
      "Epoch: 19, train_loss: 0.005753019824624062, valid_loss: 0.012066599912941456, time: [14.34], best model: 0\n",
      "Epoch: 20, train_loss: 0.005653980188071728, valid_loss: 0.012077059596776962, time: [14.69], best model: 0\n",
      "Epoch: 21, train_loss: 0.005556770134717226, valid_loss: 0.012124939821660519, time: [15.06], best model: 0\n",
      "Early Stopped at Epoch: 22\n",
      "Tested: L1_mean: 7.084802724358626, L1_std : 0.0, MAPE : 15.207725763320923, RMSE : 10.648979659552541\n"
     ]
    }
   ],
   "source": [
    "K = 3\n",
    "back_length = 3\n",
    "Clamp_A = False\n",
    "gclstm = GraphConvolutionalLSTM(K, torch.Tensor(A), FFR[back_length], A.shape[0], Clamp_A=Clamp_A, output_last = True)\n",
    "gclstm, gclstm_loss = TrainModel(gclstm, train_dataloader, valid_dataloader, num_epochs = 200)\n",
    "gclstm_test = TestModel(gclstm, test_dataloader, max_speed )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
